---
title: 'Analysis: sec1east'
author: "Paul Hegedus"
output: html_document
---
This page documents the field specific analysis of 'sec1east'. This includes analysis for both years of experimentation. Data is split into training and validation datasets using 60 and 40 percent of the data, respectively. For each year, each model is fit to the response variable using backwards AIC based model selection. The final model is used to predict the response variable (yield, protein, net-return) in the validation dataset and for calculating a RMSE for each model. Each variable is then adjusted +/-10% and the response is predicted and compared to the default predictions to determine the most elastic covariates related to each response variable.

For each final model, the AIC and RMSE are recorded in a table with the field, year, AIC, RMSE, and resposne variable. The most sensitive parameters for each model, resposne variable, and year are also recorded. These are used to asses patterns in drivers of the response variable between years in the same field and between fields in the same year, see [ESA Analysis](esa_analysis.html).

```{r}
library(magrittr)
library(ggplot2)
library(dplyr)
source("R/importCleanSelectFuns.R")
source("R/analysisFuns.R")

field_name <- "sec1east"

out_folder <- paste0("results/", field_name," /") 
field_dat <- list.files("prepped")[grepl(field_name, list.files("prepped"))]
```

# 2019 sec1east
Analysis for the most recent year on record for the field. The section below imports the data from the specified field and year, explores the relationship between each response and as-applied N, and evaluates the correlations between covariates and responses. Depending on the correlations between parameters, covariates may be omitted. Data is centered if desired, and then 60% of the data is used for training and 40% is used for validation. 

```{r}
year <- "2019"
raw_name <- field_dat[grepl(year, field_dat)]
```

## Import and Explore Data
Import the specified field and year data and summarize the data. See exploratory figures for response variables plotted against each explanatory variable.

```{r}
dat <- impDat(raw_name, "prepped")
summary(dat)
```

Before looking at correlations, parameters with singular gradients are assessed and removed. At this point, the duplicate X and Y columns are removed.

```{r}
zv <- apply(dat, 2, function(x) length(unique(x)) == 1)
dfr <- as.data.frame(dat)[, !zv] #(suppose df is the name of your dataset)
dfr <- dfr[, -grep("X|Y", names(dfr))]
```


Now, explore correlations between variables within the dataset to assess any potential covariance issues between variables in analysis. A level of 0.7 is used as a threshold in which to remove a variable due to multicollinearity. 

```{r, fig.height=6.5, fig.width=12}
cor_mat <- dfr %>%
  as.matrix() %>% 
  cor(use = "pairwise.complete.obs") %>%
  round(2)
psych::cor.plot(cor_mat, main=paste0(field_name," Correlation Matrix"), upper=F)
```

Remove any covariates if necessary.

```{r}

```


By default, all of the covariate data except latitude and longitude are centered to decrease the difference in magnitude between the scales of variables (i.e NDVI = 0 - 1, elev = 1500 - 2000). The response variables are also centered so that the variance from the mean is modeled. This allows inference on covariate influence on the variance of the responses around the mean. 

```{r}
dfc <- dfr %>% dplyr::select(-c("x", "y"))
for (i in 1:ncol(dfc)) {
  dfc[, i] <- dfc[, i] - mean(dfc[, i], na.rm = T)
}
names(dfc) <- paste0("cent_", names(dfc))
dfa <- cbind(dfr, dfc)
```


The last step before analysis is to split the data into training and validation datasets. 60% of the data is used for training models, while the validation dataset is reserved for assessing the ability of the final model to predict actual values.

```{r}
dat_list <- dualSplit(dfa, 0.6)
dt <- dat_list$trn
dv <- dat_list$val
```

## Generalized Additive Model
* backwards AIC based model selection
* check diagnostics
* make any adjustments
* predict to validations set
* calculate RMSE
* output plots

* sensitivity analysis
* save outputs

## Non-Linear Logistic Model
* backwards AIC based model selection
* evaluate assumptions
* predict to validations set
* calculate RMSE
* output plots

* sensitivity analysis
* save outputs

## Mixed Effects Model
* backwards AIC based model selection
* evaluate assumptions
* predict to validations set
* calculate RMSE
* output plots

* sensitivity analysis
* save outputs

## Save Outputs
* save each table output
* etc.

# 2017 sec1east
Analysis for the most recent year on record for the field. The section below imports the data from the specified field and year, explores the relationship between each response and as-applied N, and evaluates the correlations between covariates and responses. Depending on the correlations between parameters, covariates may be omitted. Data is centered if desired, and then 60% of the data is used for training and 40% is used for validation. 

```{r}

```

## Import and Explore Data
* bring in data
* plot each response vs. N
* explore correlations 
* remove any covariates
* center? 
* split data

## Generalized Additive Model
* backwards AIC based model selection
* evaluate assumptions
* predict to validations set
* calculate RMSE
* output plots

* sensitivity analysis
* save outputs

## Non-Linear Logistic Model
* backwards AIC based model selection
* evaluate assumptions
* predict to validations set
* calculate RMSE
* output plots

* sensitivity analysis
* save outputs

## Mixed Effects Model
* backwards AIC based model selection
* evaluate assumptions
* predict to validations set
* calculate RMSE
* output plots

* sensitivity analysis
* save outputs

## Save Outputs
* save each table output
* etc.







